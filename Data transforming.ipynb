{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: c:\\Cricsheet\\downloads\\odis_json.zip to c:\\Cricsheet\\extracted\\odis_json\n",
      "Extracted: c:\\Cricsheet\\downloads\\tests_json.zip to c:\\Cricsheet\\extracted\\tests_json\n",
      "Processing Odis matches...\n",
      "Odis DataFrame shape: (2860, 3071)\n",
      "Processing Tests matches...\n",
      "Tests DataFrame shape: (845, 1449)\n",
      "Saved Odis matches to c:\\Cricsheet\\datasets\\odis_matches.csv\n",
      "Saved Tests matches to c:\\Cricsheet\\datasets\\tests_matches.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths\n",
    "download_dir = os.path.join(os.getcwd(), \"downloads\")\n",
    "extracted_dir = os.path.join(os.getcwd(), \"extracted\")\n",
    "output_dir = os.path.join(os.getcwd(), \"datasets\")\n",
    "\n",
    "os.makedirs(extracted_dir, exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def unzip_files(zip_dir, output_dir):\n",
    "    \"\"\"Extract all zip files in the directory.\"\"\"\n",
    "    for file_name in os.listdir(zip_dir):\n",
    "        if file_name.endswith(\".zip\"):\n",
    "            zip_path = os.path.join(zip_dir, file_name)\n",
    "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                extract_to = os.path.join(output_dir, os.path.splitext(file_name)[0])\n",
    "                os.makedirs(extract_to, exist_ok=True)\n",
    "                zip_ref.extractall(extract_to)\n",
    "                print(f\"Extracted: {zip_path} to {extract_to}\")\n",
    "\n",
    "def clean_dataframe(df):\n",
    "    \"\"\"\n",
    "    Preprocess the DataFrame:\n",
    "    - Simplify column names\n",
    "    - Handle missing values\n",
    "    - Remove duplicates\n",
    "    - Normalize data types\n",
    "    \"\"\"\n",
    "    # Simplify column names\n",
    "    df.columns = [\n",
    "        col.replace('meta.', '')\n",
    "           .replace('info.', '')\n",
    "           .replace('outcome.', 'outcome_')\n",
    "           .replace('event.', 'event_')\n",
    "           .replace('officials.', 'officials_')\n",
    "           .replace('.', '_')\n",
    "           .replace('info.', '')\n",
    "           .replace('registry.people.', '')\n",
    "           .replace('players.', 'players_')\n",
    "           .replace('.', '_')  # Replace remaining dots with underscores\n",
    "        for col in df.columns\n",
    "    ]\n",
    "    \n",
    "    df.columns = ['_'.join(col.split('.')[-2:]) for col in df.columns]\n",
    "\n",
    "\n",
    "    # Convert non-hashable types to strings\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].apply(lambda x: str(x) if isinstance(x, (list, dict)) else x)\n",
    "\n",
    "    # Handle missing values\n",
    "    df.fillna({\n",
    "        'player_of_match': 'Unknown',\n",
    "        'result': 'No Result'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Drop columns with more than 50% missing values\n",
    "    missing_threshold = 0.5 * len(df)\n",
    "    df.dropna(axis=1, thresh=missing_threshold, inplace=True)\n",
    "\n",
    "    # Drop duplicate rows\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Normalize dates if 'dates' column exists\n",
    "    if 'dates' in df.columns:\n",
    "        df['dates'] = pd.to_datetime(df['dates'], errors='coerce')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def process_json_files(extracted_dir):\n",
    "    \"\"\"Process JSON files and return cleaned DataFrames for each match type.\"\"\"\n",
    "    dataframes = {}\n",
    "\n",
    "    for match_type_dir in os.listdir(extracted_dir):\n",
    "        match_type_path = os.path.join(extracted_dir, match_type_dir)\n",
    "        if os.path.isdir(match_type_path):\n",
    "            match_type = match_type_dir.split('_')[0].capitalize()\n",
    "            print(f\"Processing {match_type} matches...\")\n",
    "            match_dataframes = []\n",
    "\n",
    "            for json_file in os.listdir(match_type_path):\n",
    "                if not json_file.endswith(\".json\"):\n",
    "                    continue\n",
    "\n",
    "                json_path = os.path.join(match_type_path, json_file)\n",
    "                try:\n",
    "                    with open(json_path, 'r') as file:\n",
    "                        match_data = json.load(file)\n",
    "                        df = pd.json_normalize(match_data)  # Flatten nested JSON\n",
    "                        df = clean_dataframe(df)  # Clean and preprocess the DataFrame\n",
    "                        match_dataframes.append(df)\n",
    "                except (json.JSONDecodeError, KeyError) as e:\n",
    "                    print(f\"Error processing {json_file}: {e}\")\n",
    "\n",
    "            # Combine all DataFrames for the match type\n",
    "            dataframes[match_type] = pd.concat(match_dataframes, ignore_index=True) if match_dataframes else pd.DataFrame()\n",
    "            print(f\"{match_type} DataFrame shape: {dataframes[match_type].shape}\")\n",
    "\n",
    "    return dataframes\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Unzip files\n",
    "    unzip_files(download_dir, extracted_dir)\n",
    "\n",
    "    # Step 2: Process JSON files into cleaned DataFrames\n",
    "    dataframes = process_json_files(extracted_dir)\n",
    "\n",
    "    # Step 3: Save the cleaned DataFrames as CSVs\n",
    "    for match_type, df in dataframes.items():\n",
    "        file_path = os.path.join(output_dir, f\"{match_type.lower()}_matches.csv\")\n",
    "        df.to_csv(file_path, index=False)\n",
    "        print(f\"Saved {match_type} matches to {file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
